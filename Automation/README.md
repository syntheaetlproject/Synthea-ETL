# AWS Synthea Healthcare Data Pipeline

This guide will walk you through setting up a complete ETL pipeline for **Synthea synthetic healthcare data** using:
- AWS Glue (ETL)
- AWS Lambda (trigger)
- Amazon S3 (storage)
- Amazon Athena (query)
- Power BI (visualization)

---

## Task 1: Generate Synthea Data (CSV Format)

### 1Ô∏è‚É£ Download and Setup Synthea
- Download the Synthea project ZIP from GitHub:  
    https://github.com/synthetichealth/synthea

- Extract the folder and navigate to:

```
synthea/src/main/resources/synthea.properties
```

- **Enable CSV Output**:  
  Open `synthea.properties` and set:
  ```properties
  exporter.csv.export = true
  ```

### Run the Synthea Generator
Open terminal in the Synthea root directory and run:

```bash
./run_synthea -p <NUMBER_OF_PATIENTS>
```

üìÅ After completion, you'll see an `output/csv` folder with **18 CSV files**.

---

## Task 2: AWS Glue + Lambda Automation

### Create an S3 Bucket

- Go to **S3** and create a bucket (e.g., `synthea-data-pipeline`)
- Inside it, create these folders:
  ```
  /incoming/
  /processed/
  /errors/
  ```

> üì∑ Refer to image below for example folder structure:

![S3 Folder Structure](images/s3_structure.png)

---

### Create AWS Glue Jobs

- Go to **AWS Glue ‚Üí Jobs** and create Glue ETL scripts
- Set:
  - **Number of Workers**: e.g., 10
  - **Worker Type**: G.1X or G.2X
  - **Concurrency**: Max 18 for Job 1
  - Add required **environment variables**

---

### Add Lambda Trigger

- Create a **Lambda function** to trigger Glue Job
- Increase Lambda timeout (e.g., 5 mins or more)
- Grant it proper **IAM permissions** to start Glue jobs

> **Attach the following IAM Policies**:
- `AWSGlueServiceRole`
- `AmazonS3FullAccess`
- `AWSLambdaBasicExecutionRole`
- `CloudWatchLogsFullAccess`

---

### Add Event Notification to S3

Go to:

**S3 ‚Üí Properties ‚Üí Event Notifications ‚Üí Add Event**

- Name: `TriggerLambda`
- Event Type: `PUT`
- Prefix: `incoming/`
- Destination: Select your Lambda function

---

### Create Glue Workflow

Go to **AWS Glue ‚Üí Workflows**  
- Create a new workflow and attach your Glue jobs in sequence.

> üì∑ Refer to the image below for an example Glue Workflow setup:

![Glue Workflow Setup](images/glue_workflow.png)

---

## Task 3: Run the Pipeline

### Add Input Data

- Upload your **18 CSV files** into `incoming/` folder in your S3 bucket.

---

### Monitor Execution

- **Lambda Logs**:  
  Go to **CloudWatch ‚Üí Log Groups ‚Üí /aws/lambda/<your_lambda>**

- **Glue Job Monitoring**:  
  Go to **AWS Glue ‚Üí Jobs ‚Üí Monitor Runs**

>  Refresh the page manually if Glue run status doesn‚Äôt auto-update.

---

###  Query with Amazon Athena

1. Go to **Athena ‚Üí Settings** and set query result location (e.g., `s3://synthea-data-pipeline/athena-results/`)
2. Select the database created by Glue jobs
3. Write SQL queries to explore the data

---


## üßæ Notes

- Always test Lambda with smaller datasets first
- Ensure S3, Glue, and Lambda are in the **same region**
- Update concurrency and memory limits based on job performance
- Monitor failed job runs in **CloudWatch Logs**
